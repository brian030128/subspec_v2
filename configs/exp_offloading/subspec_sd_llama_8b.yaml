method: subspec_sd
vram_limit_gb: 8
seed: 0
device: cuda:0
max_length: 2048

llm_path: meta-llama/Llama-3.1-8B-Instruct

do_sample: false
temperature: 0

generator_kwargs:
  prefill_chunk_size: 256
  verify_method: exact
  verify_kwargs: {}

draft_params:
  temperature: 0.2
  max_depth: 48
  topk_len: 6

recipe:
  class_path: specdecodes.helpers.recipes.subspec.hqq_4bit_postspec:Recipe

cache_implementation: static
warmup_iter: 3
compile_mode: max-autotune
